{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Clustering, Viz, Assessing Reconstruction</b></font><br>\n",
    "Now that we've gotten a dictionary, let's cluster some stuff. We'll load the dictionary V, the data and its labels, and do sparse encoding on the fly. Note: can I write several of the steps into one def?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import pylab as pl\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "#import re\n",
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import csv\n",
    "from __future__ import division\n",
    "import itertools\n",
    "\n",
    "from skimage import io, filters, util, data, img_as_float\n",
    "import scipy\n",
    "import brewer2mpl\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, SparseCoder, sparse_encode, PCA\n",
    "from sklearn.feature_extraction.image import extract_patches_2d, PatchExtractor, reconstruct_from_patches_2d\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage.transform import downscale_local_mean\n",
    "\n",
    "#from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import skynet.pipeline\n",
    "import skynet.utils\n",
    "import skynet.dl_utils as dl\n",
    "import skynet.viz as viz\n",
    "import skynet.sparse_encoding as se\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram, leaves_list\n",
    "\n",
    "data_path = \"/Users/don/Documents/patch_data/\"\n",
    "dl_path = \"/Users/don/Documents/DL/\"\n",
    "\n",
    "#Tell numpy to skip division by zero in broadcasting\n",
    "np.seterr(divide = 'ignore', invalid = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the desired dictionary\n",
    "V_name = 'V46a1e-1'; V_fn = V_name+'.npy'\n",
    "V_ls = np.load(dl_path+V_fn)\n",
    "V = V_ls[1]; dataset_fn = V_ls[0][0]\n",
    "print(V_ls[0])\n",
    "\n",
    "d0 = pickle.load(open(data_path+'p1_tr.p',\"rb\"))\n",
    "d1 = pickle.load(open(data_path+'p1_te.p',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "alfa_ls = [1,2,4,8,16,32]\n",
    "\n",
    "X_dict1 = se.patch_and_sparse_encode(d0, V)\n",
    "X_dict2 = se.patch_and_sparse_encode(d1, V)\n",
    "print(\"\")\n",
    "print(\"Done in %.2fs\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = (V - V.min())/(V.max() - V.min())\n",
    "\n",
    "#imshow the learnt dictionary\n",
    "plt.figure(figsize = (8, 8))\n",
    "for i, comp in enumerate(W[:100]):\n",
    "    plt.subplot(10, 10, i+1)\n",
    "    plt.imshow(comp.reshape(30,30,3))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.suptitle('%s\\n DL Params: %s(%s), ncols = %s, n_iter = %s ' \n",
    "                 % (V_name, V_ls[0][2], V_ls[0][3], V_ls[0][1], V_ls[0][4]))\n",
    "    plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Reconstruction Error</b></font><br>First we manually eyeball some reconstructions, then do some calculations for reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get error of all the data\n",
    "# First get all the reconstructions, XV_dict\n",
    "alfa_ls = [1,2,4,8,16,32]\n",
    "XV_dict1 = {1:'', 2:'', 4:'', 8:'', 16:'', 32:''}\n",
    "XV_dict2 = {1:'', 2:'', 4:'', 8:'', 16:'', 32:''}\n",
    "\n",
    "for alfa in alfa_ls:\n",
    "    recon = np.dot(X_dict1[alfa], V)\n",
    "    recon = (recon - recon.min())/(recon.max() - recon.min())\n",
    "    XV_dict1[alfa] = recon\n",
    "    \n",
    "    recon = np.dot(X_dict2[alfa], V)\n",
    "    recon = (recon - recon.min())/(recon.max() - recon.min())\n",
    "    XV_dict2[alfa] = recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that error computations also need normalized image data\n",
    "\n",
    "err_tr_dict = {1:[], 2:[], 4:[], 8:[], 16:[], 32:[]}\n",
    "err_te_dict = {1:[], 2:[], 4:[], 8:[], 16:[], 32:[]}\n",
    "# Separate arrays to contain the patch-level error\n",
    "err_arr_dict1 = {}\n",
    "err_arr_dict2 = {}\n",
    "\n",
    "# Let's not record the individual error array for now - just mu and sigma\n",
    "img_data_n = get_img_data(d0)\n",
    "for k in list(XV_dict1.keys()):\n",
    "    err_arr, mu, sigma = viz.get_reconstruction_error(XV_dict1[k], img_data_n, k)\n",
    "    err_arr_dict1[k] = err_arr\n",
    "    loss_arr = viz.get_loss(X_dict1[k], XV_dict1[k], img_data_n, k)\n",
    "    err_tr_dict[k]=[mu, sigma, np.average(loss_arr)]\n",
    "\n",
    "\n",
    "img_data_n = get_img_data(d1)\n",
    "for k in list(XV_dict2.keys()):\n",
    "    err_arr, mu, sigma = viz.get_reconstruction_error(XV_dict2[k], img_data_n, k)\n",
    "    err_arr_dict2[k] = err_arr\n",
    "    loss_arr = viz.get_loss(X_dict2[k], XV_dict2[k], img_data_n, k)\n",
    "    err_te_dict[k]=[mu, sigma, np.average(loss_arr)]\n",
    "\n",
    "err_dict = {'tr_err':err_tr_dict, 'te_err':err_te_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err_tr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err_te_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the sparse dict\n",
    "# sps_dict fn: <dict name>_<encoding algo>\n",
    "# sps_dict cols: 1, 2, 4, 8, 16, 32, 64, img_idx, moa\n",
    "sps_dict1 = X_dict1.copy()\n",
    "for k in list(sps_dict1.keys()):\n",
    "    sps_dict1[k] = list(sps_dict1[k])\n",
    "# Let's just hope that patch-level order is preserved\n",
    "sps_dict1['img_idx'] = list(d0['img_idx'])\n",
    "sps_dict1['moa'] = list(d0['moa'])\n",
    "sps_dict1['cpd'] = list(d0['cpd'])\n",
    "sps_dict1['cc'] = list(d0['cc'])\n",
    "sps_df1 = pd.DataFrame(sps_dict1)\n",
    "\n",
    "\n",
    "sps_dict2 = X_dict2.copy()\n",
    "for k in list(sps_dict2.keys()):\n",
    "    sps_dict2[k] = list(sps_dict2[k])\n",
    "# Let's just hope that patch-level order is preserved\n",
    "sps_dict2['img_idx'] = list(d1['img_idx'])\n",
    "sps_dict2['moa'] = list(d1['moa'])\n",
    "sps_dict2['cpd'] = list(d1['cpd'])\n",
    "sps_dict2['cc'] = list(d1['cc'])\n",
    "sps_df2 = pd.DataFrame(sps_dict2)\n",
    "\n",
    "\n",
    "save_str = data_path + V_name + '_lars.p'\n",
    "print(save_str)\n",
    "\n",
    "# For g6s, because it didn't get a tr/te split\n",
    "#pickle.dump([sps_df1, err_tr_dict], open(save_str, 'wb'))\n",
    "pickle.dump([sps_df1, sps_df2, err_dict], open(save_str, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Loading Block</b></font><br>Not working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_encoding_fn = 'V46a01_lars'\n",
    "mydata = np.load(data_path+dict_encoding_fn+'.p')\n",
    "sps_tr = mydata[0]\n",
    "sps_te = mydata[1]\n",
    "err_dict = mydata[2]\n",
    "print(sps_tr.shape)\n",
    "print(sps_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_dict1 = {1:'', 2:'', 4:'', 8:'', 16:'', 32:'', 64:''}\n",
    "X_dict2 = {1:'', 2:'', 4:'', 8:'', 16:'', 32:'', 64:''}\n",
    "alfa_ls = [1,2,4,8,16,32]\n",
    "\n",
    "for alfa in alfa_ls:\n",
    "    X_dict1[alfa] = np.array(list(sps_tr[alfa]))\n",
    "    X_dict2[alfa] = np.array(list(sps_te[alfa]))\n",
    "    \n",
    "# Run the cell above to get back XV_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Histogram of Testing Reconstruction Error</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot histogram of reconstruction errors\n",
    "# Can only plot 3 values of alpha at a time, because your screen isn't fat enough\n",
    "# You'll need the err_arr_dicts{} from the RECONSTRUCTION block above\n",
    "alfa_ls = [1,2,4,8,16,32]\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.suptitle(\"D = %s\\n\\nx-axis = Test set Reconstruction error (euc dist)\\ny-axis = ???\" % V_name, fontsize=14)\n",
    "for i in range(len(alfa_ls)):\n",
    "    plt.subplot(3, 2, i+1)\n",
    "    plt.title('Alpha = %s' % alfa_ls[i])\n",
    "    plt.hist(err_arr_dict2[alfa_ls[i]], 30, normed=1)\n",
    "    plt.xticks(np.arange(1,8))\n",
    "    plt.yticks(np.arange(7))\n",
    "    plt.subplots_adjust(0.07, 0.02, 0.92, 0.73, 0.3, 0.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Quilt Viz</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i0 = 10 # Starting index to visualize\n",
    "n_patches = 140 # Number of patches from i0 to viz\n",
    "ht = 14 # height of quilt\n",
    "p_len = 30\n",
    "a = 1\n",
    "\n",
    "x_ax = np.arange(ht)\n",
    "y_ax = np.arange(int(n_patches/ht))\n",
    "\n",
    "img_data_n = img_data_n.reshape(len(img_data_n), p_len, p_len, 3)\n",
    "XV = XV_dict2[a]\n",
    "XV = XV.reshape(len(XV), p_len, p_len, 3)\n",
    "print(XV.shape)\n",
    "\n",
    "quilt_o = create_quilt(i0, n_patches, img_data_n, ht)\n",
    "quilt_XV = create_quilt(i0, n_patches, XV, ht)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(18,12))\n",
    "plt.suptitle(\"D = %s, alpha = %s, idx = %s: %s\" % (V_name, a, i0, i0+n_patches), fontsize=14)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Originals')\n",
    "plt.imshow(quilt_o)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Reconstructions (test data)')\n",
    "plt.imshow(quilt_XV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Deprecated by cell above?\"\"\"\n",
    "\n",
    "# Choose the number of patches to visualize, and the quilt dimensions\n",
    "n_patches = 25\n",
    "p_len = 30\n",
    "quilt_w = 5\n",
    "quilt_h = 5\n",
    "a=1\n",
    "\n",
    "# Select the starting index of the data subset to viz\n",
    "idx = 0\n",
    "\n",
    "block2 = []\n",
    "for patch in XV_dict1[a][idx:idx+n_patches,:]:\n",
    "    patch = patch.reshape(p_len, p_len, 3)\n",
    "    block2.append(patch)\n",
    "block2 = np.array(block2)\n",
    "print(block2.shape)\n",
    "\n",
    "block_data = []\n",
    "for patch in img_data_n[idx:idx+n_patches]:\n",
    "    patch = patch.reshape(p_len, p_len, 3)\n",
    "    block_data.append(patch)\n",
    "block_data = np.array(block_data)\n",
    "\n",
    "quilt_block = viz.form_quilt(quilt_w, block_data)\n",
    "quilt = viz.form_quilt(quilt_w, block2)\n",
    "print(quilt.shape)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Originals')\n",
    "plt.imshow(quilt_block)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Reconstructions')\n",
    "plt.imshow(quilt)\n",
    "plt.suptitle(\"D = %s, alpha = %s, idx = %s: %s\" % (V_name, a, idx, idx+n_patches), fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Viz a Single Patch, and its chosen atoms</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 100\n",
    "alfa = 1\n",
    "p_len = 30\n",
    "\n",
    "img_data = get_img_data(d0, normalize=True)\n",
    "chosen_orig = img_data[idx].reshape(p_len, p_len, 3)\n",
    "chosen_recon = XV_dict1[alfa][idx].reshape(p_len, p_len, 3)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(chosen_orig)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(chosen_recon)\n",
    "plt.title('alpha=%s'% alfa)\n",
    "plt.xticks(())\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alfa_ls = [1,2,4,8,16,32,64]\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for i in range(len(alfa_ls)):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    chosen_recon = XV_dict1[alfa_ls[i]][idx].reshape(50, 50, 3)\n",
    "    plt.imshow(chosen_recon)\n",
    "    plt.title('alpha=%s'% alfa_ls[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alfa_ls = [1,2,4,8,16,32,64]\n",
    "for alfa in alfa_ls:\n",
    "    X = X_dict1[alfa][idx]\n",
    "    #print(X_dict1[alfa][idx])\n",
    "    #print(X.shape)\n",
    "    print(len(np.flatnonzero(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only works for a small number of atoms\n",
    "X = X_dict1[32][idx].copy\n",
    "\n",
    "indices = np.flatnonzero(X)\n",
    "chosen_atoms = []\n",
    "for idx in indices:\n",
    "    chosen_atoms.append(V[idx])\n",
    "\n",
    "coef_vals = []\n",
    "for idx in indices:\n",
    "    coef_vals.append(X[idx])\n",
    "\n",
    "plt.figure(figsize=(24,10))\n",
    "for i in range(len(chosen_atoms)):\n",
    "    plt.subplot(1, 6, i+1)\n",
    "    chosen_n = (chosen_atoms[i] - chosen_atoms[i].min())/(chosen_atoms[i].max()-chosen_atoms[i].min())\n",
    "    plt.imshow(chosen_n.reshape(50,50,3))\n",
    "    plt.title(\"Atom index(coeff. val) = %s (%.2f)\" % (indices[i], coef_vals[i]))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Viz all 80 Patches of a chosen Image, and its Recon</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_patches = 80\n",
    "p_len = 50\n",
    "alfa = 4\n",
    "\n",
    "sps_df1[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 1507\n",
    "a = 16\n",
    "p_len = 50\n",
    "# Choose index 2 to see an example of selecting multiple objects from diff atoms\n",
    "\n",
    "chosen_patch = img_data[idx].reshape(p_len, p_len, 3)\n",
    "#XV1[a-1][idx].reshape(p_len, p_len, 3)\n",
    "sparse_vec = X_dict[a][idx]\n",
    "chosen_atoms = np.where(sparse_vec != 0)[0]\n",
    "chosen_coeffs = sparse_vec[(chosen_atoms)]\n",
    "\n",
    "# Get the reconstruction\n",
    "recon_full = np.dot(X_dict[a], V)\n",
    "recon = recon_full[idx].reshape(p_len, p_len, 3)\n",
    "#recon = (recon - recon.min())/(recon.max() - recon.min())\n",
    "\n",
    "atom_arrs = [chosen_patch, recon]\n",
    "for i in range(len(chosen_atoms)):\n",
    "    atom = V[chosen_atoms[i]].reshape(p_len, p_len, 3)\n",
    "    atom_arrs.append(atom)\n",
    "atom_arrs = np.array(atom_arrs)\n",
    "\n",
    "# Normalize for viz\n",
    "for i in range(len(atom_arrs)):\n",
    "    atom = (atom_arrs[i]-atom_arrs[i].min())/(atom_arrs[i].max()-atom_arrs[i].min())\n",
    "    atom_arrs[i] = atom\n",
    "    \n",
    "err = np.sqrt(np.sum((atom_arrs[0]-atom_arrs[1])**2))\n",
    "\n",
    "title_strings = ['Original', 'Reconstruction (Err='+str(err)[:6]+')']\n",
    "for i in range(len(chosen_coeffs)):\n",
    "    title_string = 'Atom index (val) = \\n'+str(chosen_atoms[i])+'('+str(chosen_coeffs[i])[:8]+')'\n",
    "    title_strings = title_strings + [title_string]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "for i in range(len(atom_arrs)):\n",
    "    plt.subplot(1,len(atom_arrs), i+1)\n",
    "    atom = (atom_arrs[i]-atom_arrs[i].min())/(atom_arrs[i].max()-atom_arrs[i].min())\n",
    "    plt.imshow(atom)\n",
    "    plt.title(title_strings[i], loc='center')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    #plt.suptitle('Dictionary learned from %d patches' % len(mydata))\n",
    "    plt.subplots_adjust(0.01, 0.3, 0.9, 0.7, 0.08, 0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's try doing the histogram error for each class\n",
    "XV_subset = XV1[0:500,:]\n",
    "mydata_subset = mydata[0:500,:]\n",
    "\n",
    "err_arr, mu, sigma = get_reconstruction_error(XV_subset, mydata_subset)\n",
    "print(\"Error (s.d.) = %.2fs (%.2fs)\" % (mu, sigma))\n",
    "\n",
    "# Plot histogram of reconstruction errors\n",
    "plt.figure(figsize = (7,6))\n",
    "plt.hist(err_arr, 30, normed=1)\n",
    "plt.xlabel('Error (Euclidean Distance)')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Biclustering, If It Helps</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_dict[2]\n",
    "\n",
    "yr, yc = viz.bicluster(X, linkage_method='average', distance_metric='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_bicluster(X, yr, yc, x_label='Sparse Encoding', y_label= 'Patches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 5><b>Scatter Plot of Nonzero Indices</b></font><br>\n",
    "Also try removing blank atoms, see what's left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select a sparse encoding, i.e. some particular value of alpha, from XV1:\n",
    "for i in range(len(err_stats_ls)):\n",
    "    print(\"%s: a=%s, %.3f (%.3f)\" % (i, alpha[i], err_stats_ls[i][1], err_stats_ls[i][2]))\n",
    "\n",
    "X = X1[3]\n",
    "a = alpha[3]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Since the number of nonzeros isn't easy to see, let's do some plots instead\n",
    "df_nz = []\n",
    "for i in range(len(X)):\n",
    "    n_nz = len(np.flatnonzero(X[i]))\n",
    "    df_nz.append(n_nz)\n",
    "df_nz = np.array(df_nz)\n",
    "print(df_nz.shape)\n",
    "\n",
    "#plt.figure(figsize=(12,8))\n",
    "#plt.bar(range(len(df_nz)), df_nz)\n",
    "\n",
    "H, dX = np.histogram(df_nz, bins=20, normed=True)\n",
    "dx = dX[1] - dX[0]\n",
    "F1 = np.cumsum(H)*dx\n",
    "plt.plot(dX[1:], F1)\n",
    "plt.xlabel('Num. of nonzero entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This works for either LARS or OMP\n",
    "r, c = np.nonzero(X)\n",
    "\n",
    "pl.figure(figsize=(15,15))\n",
    "pl.scatter(c, r, marker='.', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the binary representation of X, X_b\n",
    "# X_b.shape = X.shape\n",
    "# X_b[i, j] = 1 if X[i, j] != 0; 0 otherwise\n",
    "\n",
    "X_b = np.zeros_like(X)\n",
    "for i in range(len(X)):\n",
    "    for j in range(len(X[i])):\n",
    "        if X[i][j] != 0:\n",
    "            X_b[i][j] = 1\n",
    "\n",
    "\n",
    "# Plot of the non-zero indices of the sparse encoding, X\n",
    "# Get the indices where X is nonzero\n",
    "\n",
    "X_nz = []\n",
    "X_nz_vals = []\n",
    "for row in X:\n",
    "    nz_indices = np.where(row != 0)[0]\n",
    "    X_nz.append(nz_indices)\n",
    "    \n",
    "    vals = []\n",
    "    for j in range(len(nz_indices)):\n",
    "        vals.append(row[nz_indices[j]])\n",
    "    X_nz_vals.append(vals)\n",
    "\n",
    "X_nz = np.array(X_nz)\n",
    "X_nz_vals = np.array(X_nz_vals)\n",
    "print(X_nz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_nz = no. of nonzero coeffs in X\n",
    "n_nz = X_nz.shape[1]\n",
    "\n",
    "x_ls = []\n",
    "x_keys = []\n",
    "for i in range(n_nz):\n",
    "    x_ls.append(X_nz[:,i])\n",
    "    x_keys.append('x'+str(i))\n",
    "x_ls = np.array(x_ls)\n",
    "\n",
    "df_dict = {}\n",
    "df_dict = {x_keys[i]:x_ls[i] for i in range(n_nz)}\n",
    "df_dict['y'] = np.arange(len(X_nz))\n",
    "df_dict['label']=moa_labels\n",
    "\n",
    "\n",
    "colors = itertools.cycle(['r','g','b',\n",
    "          'c','m','y',\n",
    "          'k','#38FF24','grey',\n",
    "          '#440073','#FF33FC','#FFB833'])\n",
    "\n",
    "df = pd.DataFrame(df_dict)\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "for name, group in groups:\n",
    "    moa_color = next(colors)\n",
    "    ax.plot(group.x0,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=name\n",
    "            )\n",
    "    ax.plot(group.x1,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=''\n",
    "            )\n",
    "    \"\"\"\n",
    "    ax.plot(group.x2,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=''\n",
    "           )\n",
    "    ax.plot(group.x3,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=''\n",
    "            )\n",
    "    ax.plot(group.x4,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=''\n",
    "           )\n",
    "    ax.plot(group.x5,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=''\n",
    "            )\n",
    "    ax.plot(group.x6,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=''\n",
    "           )\n",
    "    ax.plot(group.x7,\n",
    "            group.y,\n",
    "            marker='.',\n",
    "            markersize=3,\n",
    "            linestyle='',\n",
    "            color=moa_color,\n",
    "            label=''\n",
    "            )\n",
    "\"\"\"\n",
    "    plt.xticks(np.arange(0,X.shape[1],25))\n",
    "\n",
    "    \n",
    "plt.suptitle(\"D = %s, alpha = %s\" % (V_name, a), fontsize=15)\n",
    "ax.legend(scatterpoints=1, \n",
    "          loc='upper center', \n",
    "          bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, \n",
    "          shadow=True, \n",
    "          ncol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the x most preferred atoms at class level\n",
    "a = 2\n",
    "class_idx = 2\n",
    "idx_start = class_idx*500\n",
    "idx_end = (class_idx + 1)*500\n",
    "\n",
    "X_0 = X1[a-1][idx_start:idx_end]\n",
    "X_0 = X_0.T\n",
    "\n",
    "atom_counts = []\n",
    "for i in range(len(X_0)):\n",
    "    atom_counts.append(len(np.flatnonzero(X_0[i])))\n",
    "\n",
    "#print(np.sum(atom_counts))\n",
    "atom_counts = atom_counts/np.sum(atom_counts)*100\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(atom_counts, marker='.',linewidth=0)\n",
    "plt.xlabel('Atom index')\n",
    "plt.ylabel('Frequency counts (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bmap = brewer2mpl.get_map(\"Paired\", \"Qualitative\", 12)\n",
    "color_dict = dict(zip(list(set(moa_labels)), bmap.mpl_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try pruning universal atoms\n",
    "# First convert X to a binary matrix X_b, where X_b[i, j] == 1 if X[i, j] != 0, 0 otherwise\n",
    "X_b = []\n",
    "for row in X:\n",
    "    nz_indices = np.flatnonzero(row)\n",
    "    nz_row = np.zeros(X.shape[1])\n",
    "    for nz_index in nz_indices:\n",
    "        nz_row[nz_index] = 1\n",
    "    X_b.append(nz_row)\n",
    "\n",
    "X_b = np.array(X_b)\n",
    "print(X_b.shape)\n",
    "\n",
    "atom_df = np.sum(X_b, axis=0)\n",
    "atom_df = atom_df/len(X_b)\n",
    "\n",
    "plt.plot(atom_df)\n",
    "\n",
    "for i in range(len(atom_df)):\n",
    "    if atom_df[i] > 0.1:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5><b>Clustering: PCA, K-means, tSNE</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the explained variance ratios\n",
    "# Not good...the first 2 PCs only account for about 7% of variance each\n",
    "n_PCs=2\n",
    "x_pca_obj = PCA(n_components = n_PCs)\n",
    "x_pca_obj_fit = x_pca_obj.fit_transform(Z)\n",
    "POV = x_pca_obj.explained_variance_ratio_\n",
    "for i in range(n_PCs):\n",
    "    print(POV[i])\n",
    "\n",
    "print(\"Total explained variances =\",sum(POV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do PCA on data, X\n",
    "n_PCs = 2\n",
    "X_redux = PCA(n_components = n_PCs).fit_transform(Z)\n",
    "X_redux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bmap = brewer2mpl.get_map(\"Paired\", \"Qualitative\", 12)\n",
    "color_scale2 = dict(zip(list(set(moa_labels)), bmap.mpl_colors))\n",
    "\n",
    "x = X_redux[:,0]\n",
    "y = X_redux[:,1]\n",
    "\n",
    "df0 = pd.DataFrame(dict(x=x, y=y,label=moa_labels))\n",
    "\n",
    "groups = df0.groupby('label')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.scatter(group.x, \n",
    "               group.y, \n",
    "               marker='.',\n",
    "               lw=0,\n",
    "               s=45, \n",
    "               label=name,\n",
    "              c=color_scale2[name])\n",
    "    \n",
    "ax.legend(scatterpoints=1, \n",
    "          loc='upper center', \n",
    "          bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, \n",
    "          shadow=True, \n",
    "          ncol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Do k means on the transformed data\n",
    "kmeans = KMeans(n_clusters=12, n_init=10) #estimator object\n",
    "km_fit = kmeans.fit_transform(X_redux)\n",
    "\n",
    "km_labels = kmeans.labels_\n",
    "#type(km_labels) np.array\n",
    "#for i in range(len(km_labels)):\n",
    "#    print(\"%s: %s\" % (i, km_labels[i]))\n",
    "\n",
    "print(len(list(set(km_labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bmap = brewer2mpl.get_map(\"Paired\", \"Qualitative\", 12)\n",
    "color_scale = dict(zip(list(set(km_labels)), bmap.mpl_colors))\n",
    "color_scale2 = dict(zip(list(set(moa_labels2)), bmap.mpl_colors))\n",
    "\n",
    "colors = itertools.cycle(['r','g','b',\n",
    "          'c','m','y',\n",
    "          'k','#38FF24','grey',\n",
    "          '#440073','#FF33FC','#FFB833'])\n",
    "\n",
    "\n",
    "df_km = pd.DataFrame(dict(x=X_redux[:,0], \n",
    "                          y=X_redux[:,1],\n",
    "                          label=moa_labels2))\n",
    "\n",
    "groups = df_km.groupby('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k-means plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.scatter(group.x, \n",
    "               group.y, \n",
    "               s=45, \n",
    "               label=name,\n",
    "               marker='o',\n",
    "               linewidth=0,\n",
    "               c=color_scale2[name])\n",
    "    \n",
    "ax.legend(scatterpoints=1, \n",
    "          loc='upper center', \n",
    "          bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, \n",
    "          shadow=True, \n",
    "          ncol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = 600\n",
    "perp = 50\n",
    "ee = 1\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "tsne_m0 = TSNE(n_components=2, \n",
    "               learning_rate = lr,\n",
    "               perplexity=perp,\n",
    "               early_exaggeration=ee,\n",
    "               random_state=0,\n",
    "              verbose=1)\n",
    "X_tsne = tsne_m0.fit_transform(Z)\n",
    "\n",
    "print(\"Done in %.2fs\" % (time.time()-t0))\n",
    "# Takes awhile: about 300s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bmap = brewer2mpl.get_map(\"Paired\", \"Qualitative\", 12)\n",
    "color_scale2 = dict(zip(list(set(moa_labels2)), bmap.mpl_colors))\n",
    "\n",
    "df_tsne = pd.DataFrame(dict(x=X_tsne[:,0], \n",
    "                            y=X_tsne[:,1],\n",
    "                            label=moa_labels2))\n",
    "\n",
    "groups = df_tsne.groupby('label')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.scatter(group.x, \n",
    "               group.y, \n",
    "               s=45, \n",
    "               label=name,\n",
    "               marker='o',\n",
    "               linewidth=0,\n",
    "               c=color_scale2[name])\n",
    "    ax.set_title('PCA50 --> tSNE2 clusters\\n'+\\\n",
    "                 'Based on DL: 200, omp2, 30000 iters\\n'+\\\n",
    "                 'tSNE2 params:perplexity = %s, early exaggeration = %s' \n",
    "                 % (perp, ee))\n",
    "    \n",
    "ax.legend(scatterpoints=1, \n",
    "          loc='upper center', \n",
    "          bbox_to_anchor=(0.5, -0.05),\n",
    "          fancybox=True, \n",
    "          shadow=True, \n",
    "          ncol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = [10.032, 10.074, 8.018, 6.872, 7.208, 11.278, 11.757]\n",
    "v2 = [9.949, 9.61, 8.656, 9.948, 11.698, 13.675, 16.103]\n",
    "v3 = [11.381, 11.132, 10.22, 8.697, 9.286, 10.819, 12.571]\n",
    "v4 = [12.308, 11.262, 10.437, 9.704, 7.598, 7.623, 10.927]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = ['1','2','4','8','16','32','64']\n",
    "y = [1, 2, 4, 8, 16, 32, 64]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "xticks=()\n",
    "ax.set_xlabel(\"alpha for sparse encoding (LARS)\")\n",
    "ax.set_ylabel('Mean reconstruction error using Euc. Dist.')\n",
    "line1, = plt.plot(y, v1, marker='o', label='32000')\n",
    "line2, = plt.plot(y, v2, marker='o', label='64000')\n",
    "line3, = plt.plot(y, v3, marker='o', label='96000')\n",
    "line4, = plt.plot(y, v4, marker='o', label='128000')\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=4)}, loc='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alfa_idx = 3\n",
    "x1 = [v1[0], v2[0], v3[0], v4[0]]\n",
    "x = [v1[3], v2[3], v3[3], v4[3]] # Error for n_nz = 8\n",
    "plt.plot([32, 64, 96, 128], x1, marker='o', linewidth=0.5)\n",
    "plt.scatter([32, 64, 96, 128], x, marker='o')\n",
    "plt.title('Sparse encoding error for LARS, n_nonzero_coefs = 16')\n",
    "plt.xlabel('No. of iterations (in thousands)')\n",
    "plt.ylabel('Mean Error (Euc. Dist)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v_all = [v1, v2, v3, v4]\n",
    "v_all = np.array(v_all)\n",
    "v_all.T\n",
    "y = [32, 64, 96, 128]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "xticks=()\n",
    "ax.set_xlabel('No. of iterations (in thousands)')\n",
    "ax.set_ylabel('Mean  reconstruction error (Euc. Dist)')\n",
    "line1, = plt.plot(y, v_all.T[0], marker='o', label='alpha=1')\n",
    "line2, = plt.plot(y, v_all.T[1], marker='o', label='alpha=2')\n",
    "line3, = plt.plot(y, v_all.T[2], marker='o', label='alpha=4')\n",
    "line4, = plt.plot(y, v_all.T[3], marker='o', label='alpha=8')\n",
    "line5, = plt.plot(y, v_all.T[4], marker='o', label='alpha=16')\n",
    "line6, = plt.plot(y, v_all.T[5], marker='o', label='alpha=32')\n",
    "line7, = plt.plot(y, v_all.T[6], marker='o', label='alpha=64')\n",
    "\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=4)}, loc='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
